{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "c:\\Users\\joeag\\Documents\\venvs\\ml-env\\Lib\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    }
   ],
   "source": [
    "import os, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Methods.HEPA.train import train as train_hepa\n",
    "from Methods.HEPA.model import HEPA\n",
    "# from Methods.SSMAugPC.model import SSMAugPC\n",
    "# from Methods.SSMAugPC.train import train as train_ssmaugpc\n",
    "from Methods.BYOL.train import train as train_byol\n",
    "from Methods.BYOL.model import BYOL\n",
    "# from Methods.DINO.train import train as train_dino\n",
    "# from Methods.DINO.model import DINO\n",
    "# from Methods.SimCLR.train import train as train_simclr\n",
    "# from Methods.SimCLR.model import SimCLR\n",
    "# from Methods.SimSiam.train import train as train_simsiam\n",
    "# from Methods.SimSiam.model import SimSiam\n",
    "# from Methods.LAugPC2.train import train as train_laugpc2\n",
    "# from Methods.LAugPC2.model import LAugPC2\n",
    "# from Methods.VQVAE.train import train as train_vae\n",
    "# from Methods.VQVAE.model import VAE\n",
    "from Methods.AE.train import train as train_ae\n",
    "from Methods.AE.model import AE\n",
    "from Methods.MAE.train import train as train_mae\n",
    "from Methods.MAE.model import MAE\n",
    "from Methods.GPAViT.train import train as train_gpa\n",
    "from Methods.GPAViT.model import GPAViT\n",
    "from Methods.GPAMAE.train import train as train_gpamae\n",
    "from Methods.GPAMAE.model import GPAMAE\n",
    "from Methods.VAE.train import train as train_vae\n",
    "from Methods.VAE.model import VAE\n",
    "from Methods.Supervised.model import Supervised\n",
    "from Methods.Supervised.train import train as train_supervised\n",
    "\n",
    "from Examples.MNIST.mnist_linear_1k import mnist_linear_eval, eval_representations\n",
    "from Examples.MNIST.train import train as train_mnist\n",
    "from Utils.functional import get_optimiser, aug_interact, aug_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "dataset = datasets.MNIST(root='../Datasets/', train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root='../Datasets/', train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomCrop(20),\n",
    "    transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.RandomAffine(degrees=180, translate=(0.28, 0.28), scale=(0.75, 1.25), shear=25),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.75, 1.25), shear=25),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     img, label = train_set[i]\n",
    "#     angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "#     shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "#     img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "#     ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "#     ax.set_title(f\"Label: {label}\")\n",
    "#     ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# show before and after on each row\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15,5))\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    img, label = train_set[i+20]\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    img, label = train_set[i+20]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished training\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6750999093055725\n",
      "Best validation accuracy: 0.6774000525474548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.8907999992370605\n",
      "Best validation accuracy: 0.8848000764846802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9666000008583069\n",
      "Best validation accuracy: 0.9660000205039978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9776999950408936\n",
      "Best validation accuracy: 0.9781999588012695\n"
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'new_train',\n",
    "        'model': BYOL,\n",
    "        'save': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = cfg['model']\n",
    "    backbone = 'mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'mnist_byol'\n",
    "    experiment='byol'\n",
    "    # log_dir = None\n",
    "    log_dir = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = None\n",
    "    if cfg['save']:\n",
    "        save_dir = f'Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    if Model == VAE:\n",
    "        model = Model(1, 256).to(device)\n",
    "    elif Model == AE or Model == BYOL or Model == MAE:\n",
    "        model = Model(1).to(device)\n",
    "    else:\n",
    "        model = Model(1, 5).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        lr=3e-4, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "        \n",
    "        if isinstance(model, HEPA):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_hepa(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                stop_at=0,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                loss_fn='mse',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, GPAViT):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_gpa(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, GPAMAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train_gpa(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            optimiser = get_optimiser(\n",
    "                model, \n",
    "                'AdamW', \n",
    "                lr=3e-5, \n",
    "                wd=0.004, \n",
    "                exclude_bias=True,\n",
    "                exclude_bn=True,\n",
    "            )\n",
    "            # train_byol(\n",
    "            #     model,\n",
    "            #     optimiser,\n",
    "            #     train_set,\n",
    "            #     val_set,\n",
    "            #     num_epochs=250,\n",
    "            #     batch_size=256,\n",
    "            #     augmentation=augmentation,\n",
    "            #     beta=None,\n",
    "            #     writer=writer,\n",
    "            #     save_dir=save_dir,\n",
    "            #     save_every=5,\n",
    "            # )\n",
    "            train_mnist(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=True,\n",
    "                aug_mode='augment',\n",
    "                augment=aug_transform,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                loss_fn='mse',\n",
    "                beta=None,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.5,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, MAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_mae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                mask_ratio=0.75,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, Supervised):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train_supervised(\n",
    "                model,\n",
    "                optimiser,\n",
    "                num_epochs=250,\n",
    "                batch_size=cfg['batch_size'],\n",
    "                subset_size=cfg['subset_size'],\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        \n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "        # Evaluate inter-neuron correlations\n",
    "        rep_metrics = eval_representations(model, flatten=False)\n",
    "        if writer is not None:\n",
    "            writer.add_scalar('Encoder/test_feature_corr', rep_metrics['corr'])\n",
    "            writer.add_scalar('Encoder/test_feature_std', rep_metrics['std'])\n",
    "\n",
    "    # linear probing\n",
    "    for n in [1, 10, 100, 1000]:\n",
    "        dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "        if log_dir is not None:\n",
    "            writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "        mnist_linear_eval(model, n, writer, flatten=False, test=True)\n",
    "\n",
    "    # # Semi-supervised learning eval\n",
    "    # for n in [1, 10, 100, 1000]:\n",
    "    #     dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "    #     if log_dir is not None:\n",
    "    #         writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    #     mnist_linear_eval(model, n, writer, flatten=False, test=True, finetune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd = torch.load('Examples/MNIST/out/models/mae/mae.pth')\n",
    "model.load_state_dict(sd)\n",
    "# # linear probing\n",
    "# for n in [1, 10, 100, 1000]:\n",
    "#     dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "#     if log_dir is not None:\n",
    "#         writer = SummaryWriter(dest + f'Classifier/run_{run_no}')\n",
    "#     mnist_linear_eval(model, n, writer, flatten=False, test=True)\n",
    "\n",
    "# Semi-supervised learning eval\n",
    "for n in [1, 10, 100, 1000]:\n",
    "    dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'Classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, writer, flatten=False, test=True, finetune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate downstream classification accuracy\n",
    "# for n in [cfg['subset_size']]:\n",
    "for n in [1, 10, 100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1kmnist(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "):\n",
    "    model.eval()\n",
    "    classifier = nn.Linear(model.num_features, 10, bias=False).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.AdamW(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        classifier.train()\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        train_loss = 0\n",
    "        for _, (x, label) in loop:\n",
    "            if epoch > 0:\n",
    "                loop.set_description(f'Epoch [{epoch}/{n_epochs}]')\n",
    "                loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1], val_acc=val_accs[-1])\n",
    "\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                with torch.no_grad():\n",
    "                    x = model.encoder(x)\n",
    "                pred = classifier(x.detach())\n",
    "                loss = criterion(pred, label)\n",
    "\n",
    "            optimiser.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "        num_correct = 0\n",
    "        for x, label in val_loader:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                x = model.encoder(x)\n",
    "                pred = classifier(x)\n",
    "                loss = criterion(pred, label)\n",
    "            val_loss += loss.item()\n",
    "            num_correct += (pred.argmax(1) == label).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(num_correct / len(val_set) * 100)\n",
    "        \n",
    "    return train_losses, val_losses, val_accs\n",
    "c_t_losses, c_v_losses, c_v_accs = train_1kmnist(model, train_set, val_set, 100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, None, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'pc_vs_ae1'\n",
    "    experiment = 'mnist_linear_'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-5, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = 'LAugPC'\n",
    "    experiment = 'pc_vs_ae1'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-4, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True, \n",
    "        exclude_bn=True\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DAugPC):\n",
    "            train_daugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = HEPA\n",
    "# backbone = 'mnist_cnn'\n",
    "backbone='mnist_cnn'\n",
    "# experiment_name = f'{Model.__name__}-{backbone}'\n",
    "experiment_name = f'HEPA-0'\n",
    "# experiment = 'pc_vs_ae'\n",
    "experiment = 'final'\n",
    "# log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(1, 5, backbone=backbone).to(device)\n",
    "# model = Model(1, backbone).to(device)\n",
    "# model = Model(1, backbone=backbone).to(device)\n",
    "\n",
    "optimiser = get_optimiser(\n",
    "    model, \n",
    "    'AdamW', \n",
    "    lr=3e-4, \n",
    "    wd=0.004, \n",
    "    exclude_bias=True, \n",
    "    exclude_bn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "    if isinstance(model, HEPA):\n",
    "        train_set.transform = transforms.Compose([\n",
    "        ])\n",
    "        train_hepa(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=250,\n",
    "            batch_size=256,\n",
    "            stop_at=0,\n",
    "            train_aug_scaler='none',\n",
    "            val_aug_scaler='none',\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "\n",
    "    if isinstance(model, BYOL):\n",
    "        train_byol(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=500,\n",
    "            batch_size=256,\n",
    "            augmentation=augmentation,\n",
    "            beta=None,\n",
    "            tau_0=0.996,\n",
    "            tau_e=0.999,\n",
    "            tau_T=100,\n",
    "            normalise=True,\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "    # if isinstance(model, DINO):\n",
    "    #     train_dino(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=250,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         scale_temps=2.0,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimSiam):\n",
    "    #     train_simsiam(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         beta=None,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimCLR):\n",
    "    #     train_simclr(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         temperature=1.0,\n",
    "    #         augmentation=augmentation,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "    \n",
    "    # if isinstance(model, VAE):\n",
    "    #     train_vae(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=32,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_before = train_set[0][0].unsqueeze(0)\n",
    "img_after = F_v2.affine(img, angle=0, translate=(0, 0), scale=1.0, shear=0)\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "axes[0].imshow(img_before.squeeze().cpu(), cmap='gray')\n",
    "axes[0].set_title(f\"Before\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(img_after.squeeze().cpu(), cmap='gray')\n",
    "axes[1].set_title(f\"After\")\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    # img_pred = model.predict(img, action)\n",
    "    img_pred = model.predict(img.flatten(1), action).view(img.shape)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 1 img of each digit\n",
    "images = []\n",
    "for i in range(10):\n",
    "    while len(images) < i+1:\n",
    "        idx = torch.randint(0, len(test_set), (1,)).item()\n",
    "        if test_set.targets[idx] == i:\n",
    "            images.append(train_set[idx][0].unsqueeze(0))\n",
    "\n",
    "angles = torch.arange(-180, 180, 45).tolist()\n",
    "translate = (0,0)\n",
    "scale = 1.0\n",
    "shear = 0.0\n",
    "\n",
    "truth = {}\n",
    "pred = {}\n",
    "\n",
    "for i in range(10):\n",
    "    images_aug = []\n",
    "    img_preds = []\n",
    "    for angle in angles:\n",
    "        img_aug = F_v2.affine(images[i], angle=angle, translate=translate, scale=scale, shear=shear)\n",
    "        action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "        images_aug.append(img_aug)\n",
    "        img_preds.append(model.predict(images[i], action).view(images[i].shape))\n",
    "    \n",
    "    truth[i] = images_aug\n",
    "    pred[i] = img_preds\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(10, 8, figsize=(10,15))\n",
    "for i in range(10):\n",
    "    for j in range(8):\n",
    "        # axes[2*i, j].imshow(truth[i][j].squeeze().cpu(), cmap='gray')\n",
    "        # axes[2*i, j].axis('off')\n",
    "        # axes[2*i+1, j].imshow(pred[i][j].squeeze().cpu().detach()\n",
    "                            #   , cmap='gray')\n",
    "        # axes[2*i+1, j].axis('off')\n",
    "        axes[i, j].imshow(pred[i][j].squeeze().cpu().detach(), cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Examples.MNIST.mnist_linear_1k import get_mnist_subset_loaders\n",
    "train_loader, _ = get_mnist_subset_loaders(1, 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.functional import augment\n",
    "images , _ = next(iter(train_loader))\n",
    "images_aug, actions = [], []\n",
    "for image in images:\n",
    "    img_aug, action = augment(image, 0.25)\n",
    "    images_aug.append(img_aug)\n",
    "    actions.append(action)\n",
    "\n",
    "images_aug = torch.stack(images_aug)\n",
    "actions = torch.cat(actions, dim=0)\n",
    "images_aug.shape, actions.shape\n",
    "images_pred = model.predict(images, actions, 0)\n",
    "\n",
    "# visualise the images\n",
    "fig, axes = plt.subplots(5, 3, figsize=(3,5))\n",
    "for i in range(5):\n",
    "    axes[i, 0].imshow(images[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(images_aug[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(images_pred[i].squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    # label 1st col as original, 2nd as augmented, 3rd as predicted\n",
    "axes[0, 0].set_title('Original', fontsize=10)\n",
    "axes[0, 1].set_title('Augmented', fontsize=10)\n",
    "axes[0, 2].set_title('Predicted', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
