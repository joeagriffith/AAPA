{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms.v2.functional as F_v2\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from Utils.dataset import PreloadedDataset\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from Methods.iGPA.model import iGPA\n",
    "from Methods.BYOL.model import BYOL\n",
    "from Methods.AE.model import AE\n",
    "from Methods.MAE.model import MAE\n",
    "from Methods.GPAViT.model import GPAViT\n",
    "from Methods.GPAMAE.model import GPAMAE\n",
    "from Methods.VAE.model import VAE\n",
    "from Methods.Supervised.model import Supervised\n",
    "\n",
    "# from Examples.MNIST.mnist_linear_1k import mnist_linear_eval, eval_representations\n",
    "from Utils.train import train\n",
    "from Utils.evals import linear_probing\n",
    "from Utils.functional import get_optimiser, aug_interact, aug_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.benchmark = True\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/48000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \r"
     ]
    }
   ],
   "source": [
    "root = '../Datasets/'\n",
    "dataset = datasets.MNIST(root=root, train=True, transform=transforms.ToTensor(), download=True)\n",
    "t_dataset = datasets.MNIST(root=root, train=False, transform=transforms.ToTensor(), download=True)\n",
    "\n",
    "VAL_RATIO = 0.2\n",
    "n_val = int(len(dataset) * VAL_RATIO)\n",
    "n_train = len(dataset) - n_val\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [n_train, n_val])\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform(),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    # transforms.Pad(2),\n",
    "    # transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    # SigmoidTransform(),\n",
    "    # TanhTransform()\n",
    "])\n",
    "\n",
    "augmentation = transforms.Compose([\n",
    "    transforms.RandomCrop(20),\n",
    "    transforms.Resize(28, interpolation=transforms.InterpolationMode.NEAREST),\n",
    "    # transforms.RandomAffine(degrees=180, translate=(0.28, 0.28), scale=(0.75, 1.25), shear=25),\n",
    "    transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.75, 1.25), shear=25),\n",
    "    # transforms.GaussianBlur(3, sigma=(0.1, 2.0)),\n",
    "])\n",
    "\n",
    "train_set = PreloadedDataset.from_dataset(train_set, train_transform, device)\n",
    "val_set = PreloadedDataset.from_dataset(val_set, val_transform, device)\n",
    "test_set = PreloadedDataset.from_dataset(t_dataset, val_transform, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max value: tensor(1., device='cuda:0')\n",
      "Min value: tensor(0., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Show example images\n",
    "# fig, axes = plt.subplots(1, 10, figsize=(15,5))\n",
    "# for i, ax in enumerate(axes):\n",
    "#     img, label = train_set[i]\n",
    "#     angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "#     scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "#     shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "#     img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "#     ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "#     ax.set_title(f\"Label: {label}\")\n",
    "#     ax.axis('off')\n",
    "# plt.show()\n",
    "\n",
    "# show before and after on each row\n",
    "fig, axes = plt.subplots(2, 5, figsize=(15,5))\n",
    "for i, ax in enumerate(axes[0]):\n",
    "    img, label = train_set[i+20]\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "for i, ax in enumerate(axes[1]):\n",
    "    img, label = train_set[i+20]\n",
    "    angle = torch.rand(1).item() * 360 - 180 if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_x = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    translate_y = torch.randint(-8, 9, (1,)).item() if torch.rand(1).item() > 0.75 else 0\n",
    "    scale = torch.rand(1).item() * 0.5 + 0.75 if torch.rand(1).item() > 0.75 else 1.0\n",
    "    shear = torch.rand(1).item() * 50 - 25 if torch.rand(1).item() > 0.75 else 0\n",
    "    img = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    ax.imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    ax.axis('off')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# print max and min values\n",
    "print('Max value:', train_set.transformed_images.max())\n",
    "print('Min value:', train_set.transformed_images.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch [0/250]:   0%|          | 0/188 [00:00<?, ?it/s]  "
     ]
    }
   ],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'iGPA',\n",
    "        'model': iGPA,\n",
    "        'save': False,\n",
    "    },\n",
    "]\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = cfg['model']\n",
    "    backbone = 'mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'mnist_byol'\n",
    "    experiment='test'\n",
    "    # log_dir = None\n",
    "    log_dir = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = None\n",
    "    # save_dir = f'Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    if cfg['save']:\n",
    "        save_dir = f'Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    if Model == VAE:\n",
    "        model = Model(1, 256).to(device)\n",
    "    elif Model == AE or Model == BYOL or Model == MAE:\n",
    "        model = Model(1).to(device)\n",
    "    else:\n",
    "        model = Model(1, 5).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        lr=3e-4, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "        \n",
    "        if isinstance(model, iGPA):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=True,\n",
    "                aug_mode='augment',\n",
    "                augment=aug_interact,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_set.transform = transforms.Compose([\n",
    "            ])\n",
    "            optimiser = get_optimiser(\n",
    "                model, \n",
    "                'AdamW', \n",
    "                lr=3e-5, \n",
    "                wd=0.004, \n",
    "                exclude_bias=True,\n",
    "                exclude_bn=True,\n",
    "            )\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=True,\n",
    "                aug_mode='augment',\n",
    "                augment=aug_transform,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=False,\n",
    "                aug_mode='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=False,\n",
    "                aug_mode='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, MAE):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=False,\n",
    "                aug_mode='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, Supervised):\n",
    "            train_set.transform = transforms.Compose([\n",
    "                transforms.RandomAffine(degrees=30, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "            ])\n",
    "            train(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                dataset='mnist',\n",
    "                has_teacher=False,\n",
    "                aug_mode='none',\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        \n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # linear probing\n",
    "    for n in [1, 10, 100, 1000]:\n",
    "        dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "        run_no = 1\n",
    "        while os.path.exists(dest + f'classifier/run_{run_no}'):\n",
    "            run_no += 1\n",
    "        if log_dir is not None:\n",
    "            writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "        linear_probing(model, 'mnist', root, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.6496999859809875\n",
      "Best validation accuracy: 0.6551000475883484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.886199951171875\n",
      "Best validation accuracy: 0.878300130367279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9750999212265015\n",
      "Best validation accuracy: 0.9715000987052917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                   \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.9834999442100525\n",
      "Best validation accuracy: 0.9843000769615173\n"
     ]
    }
   ],
   "source": [
    "model = iGPA(1, 5).to(device)\n",
    "name = 'GPA'\n",
    "experiment = 'mnist'\n",
    "save_dir = f'Examples/MNIST/out/models/{experiment}/{name}.pth'\n",
    "sd = torch.load(save_dir)\n",
    "model.load_state_dict(sd)\n",
    "\n",
    "experiment = 'probing'\n",
    "experiment_name = 'GPA-L2'\n",
    "\n",
    "# linear probing\n",
    "for n in [1, 10, 100, 1000]:\n",
    "    dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "    run_no = 1\n",
    "    while os.path.exists(dest + f'classifier/run_{run_no}'):\n",
    "        run_no += 1\n",
    "    writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    linear_probing(model, 'mnist', root, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(4.4721), tensor(1.))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(1, 20)\n",
    "layer = nn.LayerNorm(x.shape[1], elementwise_affine=False)\n",
    "norm1 = layer(x)\n",
    "norm2 = F.normalize(x)\n",
    "torch.allclose(norm1, norm2)\n",
    "norm1.norm(), norm2.norm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "save_dir = f'Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "torch.save(model.state_dict(), save_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd = torch.load('Examples/MNIST/out/models/mae/mae.pth')\n",
    "model.load_state_dict(sd)\n",
    "# # linear probing\n",
    "# for n in [1, 10, 100, 1000]:\n",
    "#     dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "#     if log_dir is not None:\n",
    "#         writer = SummaryWriter(dest + f'Classifier/run_{run_no}')\n",
    "#     mnist_linear_eval(model, n, writer, flatten=False, test=True)\n",
    "\n",
    "# Semi-supervised learning eval\n",
    "for n in [1, 10, 100, 1000]:\n",
    "    dest = f'Examples/MNIST/out/logs/n{n}-{experiment}/{experiment_name}/'\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'Classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, writer, flatten=False, test=True, finetune=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate downstream classification accuracy\n",
    "# for n in [cfg['subset_size']]:\n",
    "for n in [1, 10, 100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, writer, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_1kmnist(\n",
    "        model,\n",
    "        train_set,\n",
    "        val_set,\n",
    "        n_epochs,\n",
    "        batch_size,\n",
    "):\n",
    "    model.eval()\n",
    "    classifier = nn.Linear(model.num_features, 10, bias=False).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimiser = torch.optim.AdamW(classifier.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_set, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    val_accs = []\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        classifier.train()\n",
    "        loop = tqdm(enumerate(train_loader), total=len(train_loader), leave=False)\n",
    "        train_loss = 0\n",
    "        for _, (x, label) in loop:\n",
    "            if epoch > 0:\n",
    "                loop.set_description(f'Epoch [{epoch}/{n_epochs}]')\n",
    "                loop.set_postfix(train_loss=train_losses[-1], val_loss=val_losses[-1], val_acc=val_accs[-1])\n",
    "\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                with torch.no_grad():\n",
    "                    x = model.encoder(x)\n",
    "                pred = classifier(x.detach())\n",
    "                loss = criterion(pred, label)\n",
    "\n",
    "            optimiser.zero_grad(set_to_none=True)\n",
    "            loss.backward()\n",
    "            optimiser.step()\n",
    "            train_loss += loss.item()\n",
    "        train_losses.append(train_loss / len(train_loader))\n",
    "\n",
    "        classifier.eval()\n",
    "        val_loss = 0\n",
    "        num_correct = 0\n",
    "        for x, label in val_loader:\n",
    "            with torch.autocast(device_type=device.type, dtype=torch.bfloat16):\n",
    "                x = model.encoder(x)\n",
    "                pred = classifier(x)\n",
    "                loss = criterion(pred, label)\n",
    "            val_loss += loss.item()\n",
    "            num_correct += (pred.argmax(1) == label).sum().item()\n",
    "        val_losses.append(val_loss / len(val_loader))\n",
    "        val_accs.append(num_correct / len(val_set) * 100)\n",
    "        \n",
    "    return train_losses, val_losses, val_accs\n",
    "c_t_losses, c_v_losses, c_v_accs = train_1kmnist(model, train_set, val_set, 100, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [100, 1000]:\n",
    "# for n in [100]:\n",
    "    # try:\n",
    "    #     dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    #     shutil.copytree(log_dir, dest)\n",
    "    # except:\n",
    "    #     pass\n",
    "    # dest = f'Examples/MNIST/out/logs/{experiment}/{experiment_name}-n{n}/'\n",
    "    # dest = log_dir\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(dest + f'classifier/run_{run_no}')\n",
    "    mnist_linear_eval(model, n, None, flatten=False, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "    {\n",
    "        'name': 'proj-3e-5-mse',\n",
    "    },\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = cfg['name']\n",
    "    # experiment = 'pc_vs_ae1'\n",
    "    experiment = 'mnist_linear_'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-5, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True,\n",
    "        exclude_bn=True,\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfgs = [\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    },\n",
    "    {\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "for cfg in cfgs:\n",
    "\n",
    "    Model = LAugPC\n",
    "    # backbone = 'mnist_cnn'\n",
    "    backbone='mnist_cnn'\n",
    "    experiment_name = 'LAugPC'\n",
    "    experiment = 'pc_vs_ae1'\n",
    "    log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "    save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "    save_dir = None\n",
    "    model = Model(1, 5,\n",
    "                backbone=backbone, \n",
    "                ).to(device)\n",
    "\n",
    "    optimiser = get_optimiser(\n",
    "        model, \n",
    "        'AdamW', \n",
    "        # lr = cfg['lr'],\n",
    "        lr=3e-4, \n",
    "        wd=0.004, \n",
    "        exclude_bias=True, \n",
    "        exclude_bn=True\n",
    "    )\n",
    "\n",
    "    to_train = True\n",
    "    if save_dir is not None:\n",
    "        try:\n",
    "            sd = torch.load(save_dir)\n",
    "            # change keys \"project\" to \"transition\"\n",
    "            for key in list(sd.keys()):\n",
    "                if 'project' in key:\n",
    "                    sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "            model.load_state_dict(sd)\n",
    "            to_train = False\n",
    "            print('Model loaded successfully')\n",
    "        except FileNotFoundError:\n",
    "            pass\n",
    "            print('Model not found, training new model')\n",
    "    if to_train:\n",
    "        writer = None\n",
    "        if log_dir is not None:\n",
    "            # remove reduction if exists\n",
    "            if os.path.exists(log_dir + 'encoder/reduction.csv'):\n",
    "                os.remove(log_dir + 'encoder/reduction.csv')\n",
    "            if os.path.exists(log_dir + 'classifier/reduction.csv'):\n",
    "                os.remove(log_dir + 'classifier/reduction.csv')\n",
    "\n",
    "            run_no = 1\n",
    "            while os.path.exists(log_dir + 'encoder/' + f'run_{run_no}'):\n",
    "                run_no += 1\n",
    "            writer = SummaryWriter(log_dir + 'encoder/' + f'run_{run_no}')\n",
    "\n",
    "        if isinstance(model, LAugPC):\n",
    "            train_laugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "\n",
    "        if isinstance(model, AugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, SSMAugPC):\n",
    "            train_augpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DAugPC):\n",
    "            train_daugpc(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                train_aug_scaler='none',\n",
    "                val_aug_scaler='none',\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, BYOL):\n",
    "            train_byol(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, VAE):\n",
    "            train_vae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=0.75,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, AE):\n",
    "            train_ae(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                beta=None,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        if isinstance(model, DINO):\n",
    "            train_dino(\n",
    "                model,\n",
    "                optimiser,\n",
    "                train_set,\n",
    "                val_set,\n",
    "                num_epochs=250,\n",
    "                batch_size=256,\n",
    "                augmentation=augmentation,\n",
    "                scale_temps=2.0,\n",
    "                learn_on_ss=False,\n",
    "                writer=writer,\n",
    "                save_dir=save_dir,\n",
    "                save_every=5,\n",
    "            )\n",
    "        print(f'Finished training')\n",
    "        if save_dir is not None:\n",
    "            print('Run cell again to load best (val_acc) model.')\n",
    "\n",
    "    # collect 100 of each target index from train_set.targets\n",
    "    writer = SummaryWriter(log_dir + f'classifier/run_{run_no}')\n",
    "    mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = HEPA\n",
    "# backbone = 'mnist_cnn'\n",
    "backbone='mnist_cnn'\n",
    "# experiment_name = f'{Model.__name__}-{backbone}'\n",
    "experiment_name = f'HEPA-0'\n",
    "# experiment = 'pc_vs_ae'\n",
    "experiment = 'final'\n",
    "# log_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/logs/{experiment}/{experiment_name}/'\n",
    "save_dir = f'Deep_Learning/Representation_Learning/Examples/MNIST/out/models/{experiment}/{experiment_name}.pth'\n",
    "log_dir = None\n",
    "# save_dir = None\n",
    "model = Model(1, 5, backbone=backbone).to(device)\n",
    "# model = Model(1, backbone).to(device)\n",
    "# model = Model(1, backbone=backbone).to(device)\n",
    "\n",
    "optimiser = get_optimiser(\n",
    "    model, \n",
    "    'AdamW', \n",
    "    lr=3e-4, \n",
    "    wd=0.004, \n",
    "    exclude_bias=True, \n",
    "    exclude_bn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = True\n",
    "if save_dir is not None:\n",
    "    try:\n",
    "        sd = torch.load(save_dir)\n",
    "        # change keys \"project\" to \"transition\"\n",
    "        for key in list(sd.keys()):\n",
    "            if 'project' in key:\n",
    "                sd[key.replace('project', 'transition')] = sd.pop(key)\n",
    "        model.load_state_dict(sd)\n",
    "        to_train = False\n",
    "        print('Model loaded successfully')\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "        print('Model not found, training new model')\n",
    "if to_train:\n",
    "    writer = None\n",
    "    if log_dir is not None:\n",
    "        writer = SummaryWriter(log_dir)\n",
    "    if isinstance(model, HEPA):\n",
    "        train_set.transform = transforms.Compose([\n",
    "        ])\n",
    "        train_hepa(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=250,\n",
    "            batch_size=256,\n",
    "            stop_at=0,\n",
    "            train_aug_scaler='none',\n",
    "            val_aug_scaler='none',\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "\n",
    "    if isinstance(model, BYOL):\n",
    "        train_byol(\n",
    "            model,\n",
    "            optimiser,\n",
    "            train_set,\n",
    "            val_set,\n",
    "            num_epochs=500,\n",
    "            batch_size=256,\n",
    "            augmentation=augmentation,\n",
    "            beta=None,\n",
    "            tau_0=0.996,\n",
    "            tau_e=0.999,\n",
    "            tau_T=100,\n",
    "            normalise=True,\n",
    "            learn_on_ss=False,\n",
    "            writer=writer,\n",
    "            save_dir=save_dir,\n",
    "            save_every=5,\n",
    "        )\n",
    "    # if isinstance(model, DINO):\n",
    "    #     train_dino(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=250,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         scale_temps=2.0,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimSiam):\n",
    "    #     train_simsiam(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         augmentation=augmentation,\n",
    "    #         beta=None,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    # if isinstance(model, SimCLR):\n",
    "    #     train_simclr(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=256,\n",
    "    #         temperature=1.0,\n",
    "    #         augmentation=augmentation,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "    \n",
    "    # if isinstance(model, VAE):\n",
    "    #     train_vae(\n",
    "    #         model,\n",
    "    #         optimiser,\n",
    "    #         train_set,\n",
    "    #         val_set,\n",
    "    #         num_epochs=500,\n",
    "    #         batch_size=32,\n",
    "    #         learn_on_ss=False,\n",
    "    #         writer=writer,\n",
    "    #         save_dir=save_dir,\n",
    "    #         save_every=5,\n",
    "    #     )\n",
    "\n",
    "    print(f'Finished training')\n",
    "    if save_dir is not None:\n",
    "        print('Run cell again to load best (val_acc) model.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 100 of each target index from train_set.targets\n",
    "writer = SummaryWriter(log_dir)\n",
    "mnist_linear_1k_eval(model, writer, flatten=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_before = train_set[0][0].unsqueeze(0)\n",
    "img_after = F_v2.affine(img, angle=0, translate=(0, 0), scale=1.0, shear=0)\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15,5))\n",
    "axes[0].imshow(img_before.squeeze().cpu(), cmap='gray')\n",
    "axes[0].set_title(f\"Before\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(img_after.squeeze().cpu(), cmap='gray')\n",
    "axes[1].set_title(f\"After\")\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_set[4][0].unsqueeze(0)\n",
    "model.eval()\n",
    "\n",
    "def compare(model, img, angle, translate_x, translate_y, scale, shear):\n",
    "    img_aug = F_v2.affine(img, angle=angle, translate=(translate_x, translate_y), scale=scale, shear=shear)\n",
    "    action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "    # img_pred = model.predict(img, action)\n",
    "    img_pred = model.predict(img.flatten(1), action).view(img.shape)\n",
    "    loss = F.mse_loss(img_aug, img_pred)\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axes[0].imshow(img.squeeze().cpu(), cmap='gray')\n",
    "    axes[0].set_title('Original')\n",
    "    axes[0].axis('off')\n",
    "    axes[1].imshow(img_aug.squeeze().cpu(), cmap='gray')\n",
    "    axes[1].set_title('Augmented')\n",
    "    axes[1].axis('off')\n",
    "    axes[2].imshow(img_pred.squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[2].set_title('Predicted')\n",
    "    axes[2].axis('off')\n",
    "    plt.show()\n",
    "    return loss.item()\n",
    "\n",
    "interact(compare, model=fixed(model), img=fixed(img), angle=(-180, 180), translate_x=(-8, 8), translate_y=(-8, 8), scale=(0.75, 1.25), shear=(-25, 25))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect 1 img of each digit\n",
    "images = []\n",
    "for i in range(10):\n",
    "    while len(images) < i+1:\n",
    "        idx = torch.randint(0, len(test_set), (1,)).item()\n",
    "        if test_set.targets[idx] == i:\n",
    "            images.append(train_set[idx][0].unsqueeze(0))\n",
    "\n",
    "angles = torch.arange(-180, 180, 45).tolist()\n",
    "translate = (0,0)\n",
    "scale = 1.0\n",
    "shear = 0.0\n",
    "\n",
    "truth = {}\n",
    "pred = {}\n",
    "\n",
    "for i in range(10):\n",
    "    images_aug = []\n",
    "    img_preds = []\n",
    "    for angle in angles:\n",
    "        img_aug = F_v2.affine(images[i], angle=angle, translate=translate, scale=scale, shear=shear)\n",
    "        action = torch.tensor([angle/180, translate_x/8, translate_y/8, (scale-1.0)/0.25, shear/25], dtype=torch.float32, device=img.device).unsqueeze(0).repeat(img.shape[0], 1)\n",
    "        images_aug.append(img_aug)\n",
    "        img_preds.append(model.predict(images[i], action).view(images[i].shape))\n",
    "    \n",
    "    truth[i] = images_aug\n",
    "    pred[i] = img_preds\n",
    "\n",
    "# Show example images\n",
    "fig, axes = plt.subplots(10, 8, figsize=(10,15))\n",
    "for i in range(10):\n",
    "    for j in range(8):\n",
    "        # axes[2*i, j].imshow(truth[i][j].squeeze().cpu(), cmap='gray')\n",
    "        # axes[2*i, j].axis('off')\n",
    "        # axes[2*i+1, j].imshow(pred[i][j].squeeze().cpu().detach()\n",
    "                            #   , cmap='gray')\n",
    "        # axes[2*i+1, j].axis('off')\n",
    "        axes[i, j].imshow(pred[i][j].squeeze().cpu().detach(), cmap='gray')\n",
    "        axes[i, j].axis('off')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Examples.MNIST.mnist_linear_1k import get_mnist_subset_loaders\n",
    "train_loader, _ = get_mnist_subset_loaders(1, 10, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.functional import augment\n",
    "images , _ = next(iter(train_loader))\n",
    "images_aug, actions = [], []\n",
    "for image in images:\n",
    "    img_aug, action = augment(image, 0.25)\n",
    "    images_aug.append(img_aug)\n",
    "    actions.append(action)\n",
    "\n",
    "images_aug = torch.stack(images_aug)\n",
    "actions = torch.cat(actions, dim=0)\n",
    "images_aug.shape, actions.shape\n",
    "images_pred = model.predict(images, actions, 0)\n",
    "\n",
    "# visualise the images\n",
    "fig, axes = plt.subplots(5, 3, figsize=(3,5))\n",
    "for i in range(5):\n",
    "    axes[i, 0].imshow(images[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 0].axis('off')\n",
    "    axes[i, 1].imshow(images_aug[i].squeeze().cpu(), cmap='gray')\n",
    "    axes[i, 1].axis('off')\n",
    "    axes[i, 2].imshow(images_pred[i].squeeze().cpu().detach(), cmap='gray')\n",
    "    axes[i, 2].axis('off')\n",
    "    # label 1st col as original, 2nd as augmented, 3rd as predicted\n",
    "axes[0, 0].set_title('Original', fontsize=10)\n",
    "axes[0, 1].set_title('Augmented', fontsize=10)\n",
    "axes[0, 2].set_title('Predicted', fontsize=10)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
